{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "from graph import Graph\n",
    "from utils.data_utils import data_to_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled = pd.read_csv('data/la_train_grid_with_weather.csv')\n",
    "training_data = pd.read_csv('data/LA_DATA_2018_02_to_2018_06.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_unlabeled_dataset(df):\n",
    "    df = df.rename({'day' : 'DATE'}, axis = 1)\n",
    "\n",
    "    cols = ['wind_x', 'wind_y', 'temperature', 'pressure', 'ceiling', 'dew',\n",
    "                 'precipitation_duration' , 'mean_aod','min_aod','max_aod', 'visibility',                                               \n",
    "                 'Latitudes','Longitudes','DATE']\n",
    "\n",
    "    df = df[cols]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled = format_unlabeled_dataset(unlabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_cols = 'visibility', 'precipitation_depth']\n",
    "node_cols = ['wind_x', 'wind_y', 'temperature', 'pressure', 'ceiling', 'dew', 'precipitation_duration' , 'mean_aod','min_aod','max_aod', 'pm25']                                                 \n",
    "edge_cols = ['wind_x', 'wind_y']\n",
    "date_range = sorted(training_data['DATE'].unique(), key=lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "def assign_id(weather_data):\n",
    "    ids = np.zeros(len(weather_data['Latitudes']))\n",
    "    node_pos = list(weather_data.groupby(['Latitudes', 'Longitudes']).groups)\n",
    "    for i, node in enumerate(node_pos):\n",
    "        indices_lats = weather_data['Latitudes'].values == node_pos[i][0]\n",
    "        indices_longs = weather_data['Longitudes'].values == node_pos[i][1]\n",
    "        indices = indices_lats & indices_longs\n",
    "        ids[np.argwhere(indices)] = int(i+1)\n",
    "    weather_data['STATION'] = ids\n",
    "    return weather_data\n",
    "\n",
    "def get_unlabelled_subset(unlabeled_df, dates, node_cols, edge_cols, meta_cols):\n",
    "    cols = list(set(node_cols + edge_cols + meta_cols))\n",
    "    unlabeled_df = unlabeled_df[cols]\n",
    "    unlabeled_df = unlabeled_df[unlabeled_df['DATE'].isin(dates)]\n",
    "    unlabeled_df = assign_id(unlabeled_df)\n",
    "    unlabeled_df['pm25'] = [np.nan for _ in range(len(unlabeled_df))]\n",
    "    return unlabeled_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# graph_node_features, graph_edge_features, graph_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_cols = ['wind_x', 'wind_y', 'temperature', 'pressure', 'ceiling', 'dew', 'precipitation_duration' , 'mean_aod','min_aod','max_aod']                                                 \n",
    "edge_cols = ['wind_x', 'wind_y']\n",
    "meta_cols = ['DATE', 'Latitudes', 'Longitudes']\n",
    "date_range = sorted(training_data['DATE'].unique(), key=lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "unlabeled_df = get_unlabelled_subset(unlabelled, date_range,  node_cols, edge_cols, meta_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = unlabeled_df.append(training_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date_range = sorted(dataset['DATE'].unique(), key=lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_range(file):\n",
    "    if file == 'LA_DATA_2018_02_to_2018_06.csv':\n",
    "        start = date(2018, 2, 1)\n",
    "        end = date(2018, 6, 8)\n",
    "        date_range = pd.date_range(start, end-timedelta(days=1))\n",
    "        date_range = [str(x)[:10] for x in date_range]\n",
    "        return date_range\n",
    "    else:\n",
    "        print('wrong file name.')\n",
    "\n",
    "a = get_date_range('LA_DATA_2018_02_to_2018_06.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'date_range' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/alixdanglejan-chatillon/Code/PROJECT/ECSE552_Project/test.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alixdanglejan-chatillon/Code/PROJECT/ECSE552_Project/test.ipynb#ch0000009?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m date_range:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alixdanglejan-chatillon/Code/PROJECT/ECSE552_Project/test.ipynb#ch0000009?line=1'>2</a>\u001b[0m     d \u001b[39m=\u001b[39m dataset[dataset[\u001b[39m'\u001b[39m\u001b[39mDATE\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m i]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alixdanglejan-chatillon/Code/PROJECT/ECSE552_Project/test.ipynb#ch0000009?line=2'>3</a>\u001b[0m     d\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/unlabelled/\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'date_range' is not defined"
     ]
    }
   ],
   "source": [
    "for i in date_range:\n",
    "    d = dataset[dataset['DATE'] == i]\n",
    "    d.to_csv(f\"data/unlabelled/{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_numpy1(weather_data, edge_cols, node_cols, date_range, pseudo_data=False, save=True):\n",
    "    '''Converts pandas whether data to np array. \n",
    "    Args: \n",
    "        weather_data :: pd.DataFrame\n",
    "            Dataframe containing weather data from various stations and times\n",
    "        edge_cols :: list [str]\n",
    "            List of column names to be used as edge features (ie: wind)\n",
    "        node_cols :: list [str]\n",
    "            List of column names to be used as node features\n",
    "        stations :: list [str]\n",
    "            List of station ids to select stations which have data in desired date range. (Sorted)\n",
    "        date_range :: list [str]\n",
    "            List of dates to select from weather data. \n",
    "    '''\n",
    "    if pseudo_data:\n",
    "        checkpt = 'pseudo_checkpt'\n",
    "    else:\n",
    "        checkpt = 'checkpt'\n",
    "\n",
    "    if not save or not os.path.exists(checkpt):\n",
    "        print('Checkpt doesnt exist, making it')\n",
    "        if save:\n",
    "            os.makedirs(checkpt)\n",
    "\n",
    "        stations = weather_data['STATION'].unique()\n",
    "        stations.sort()\n",
    "\n",
    "        present_dates = sorted(weather_data['DATE'].unique(\n",
    "        ), key=lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "        graph_node_features = np.empty(\n",
    "            (len(date_range), len(stations), len(node_cols)))\n",
    "        graph_edge_features = np.empty(\n",
    "            (len(date_range), len(stations), len(edge_cols)))\n",
    "        graph_labels = np.empty((len(date_range), len(stations)))\n",
    "        stations.sort()\n",
    "\n",
    "\n",
    "\n",
    "        for day_idx in range(len(date_range)):\n",
    "\n",
    "            if date_range[day_idx] not in present_dates: \n",
    "                earliest_date_with_data = day_idx\n",
    "                while date_range[earliest_date_with_data] not in present_dates:\n",
    "                    earliest_date_with_data -= 1\n",
    "                next_day_with_data = day_idx\n",
    "                while date_range[next_day_with_data] not in present_dates:\n",
    "                    next_day_with_data += 1\n",
    "\n",
    "                x = [date_range[earliest_date_with_data], date_range[next_day_with_data]]\n",
    "                vals = weather_data[weather_data['DATE'].isin(x)]\n",
    "            \n",
    "            else: \n",
    "                vals = weather_data[weather_data['DATE'] == date_range[day_idx]]\n",
    "\n",
    "            for station_idx in range(len(stations)):\n",
    "                # crop dataframe to desired date and station\n",
    "                vals = vals[vals['STATION'] == stations[station_idx]]\n",
    "\n",
    "\n",
    "                if date_range[day_idx] not in present_dates: \n",
    "                    if len(vals.index) == 0 :\n",
    "                        node_vals = weather_data[weather_data['DATE'] ==\n",
    "                                                date_range[earliest_date_with_data]][node_cols].mean().values\n",
    "                        edge_vals = weather_data[weather_data['DATE'] ==\n",
    "                                                date_range[earliest_date_with_data]][edge_cols].mean().values\n",
    "                        pm = weather_data[weather_data['DATE'] ==\n",
    "                                        date_range[earliest_date_with_data]]['pm25'].mean()  \n",
    "\n",
    "                    else:\n",
    "                        vals = vals[vals['STATION'] == stations[station_idx]]\n",
    "                        node_vals  = vals[node_cols].mean().values\n",
    "                        edge_vals = vals[edge_cols].mean().values\n",
    "                        pm = vals['pm25'].mean()\n",
    "                        \n",
    "                        if np.isnan(node_vals).any():\n",
    "                            print(len(vals.index))\n",
    "                            print(vals)\n",
    "                            assert False  \n",
    "\n",
    "\n",
    "                else: \n",
    "\n",
    "                    pm = vals['pm25'].values  # get pm\n",
    "                    # crop out edge features\n",
    "                    edge_vals = vals[edge_cols]\n",
    "                    edge_vals = np.array(edge_vals.values.tolist()).flatten()\n",
    "                    # crop out node features\n",
    "                    node_vals = vals[node_cols]\n",
    "                    # node features as array\n",
    "                    node_vals = np.array(node_vals.values.tolist()).flatten()\n",
    "\n",
    "                    # certain stations have missing data on a given day, fill with geo mean\n",
    "                    if len(node_vals) == 0:\n",
    "                        node_vals = weather_data[weather_data['DATE'] ==\n",
    "                                                date_range[day_idx]][node_cols].mean().values\n",
    "\n",
    "                    if len(pm) == 0:\n",
    "                        pm = weather_data[weather_data['DATE'] ==\n",
    "                                        date_range[day_idx]]['pm25'].mean()\n",
    "\n",
    "                    if len(edge_vals) == 0:\n",
    "                        edge_vals = weather_data[weather_data['DATE'] ==\n",
    "                                                date_range[day_idx]][edge_cols].mean().values       \n",
    "\n",
    "                graph_labels[day_idx, station_idx] = pm\n",
    "                graph_node_features[day_idx, station_idx] = node_vals\n",
    "                graph_edge_features[day_idx, station_idx] = edge_vals\n",
    "\n",
    "        if save:\n",
    "            print('Creating checkpoint')\n",
    "            np.save(os.path.join(checkpt, 'graph_node_features'),\n",
    "                    graph_node_features)\n",
    "            np.save(os.path.join(checkpt, 'graph_edge_features'),\n",
    "                    graph_edge_features)\n",
    "            np.save(os.path.join(checkpt, 'graph_labels'), graph_labels)\n",
    "\n",
    "    else:\n",
    "        print('Found Checkpoint, loading')\n",
    "        graph_node_features = np.load(\n",
    "            os.path.join(checkpt, 'graph_node_features.npy'))\n",
    "        graph_edge_features = np.load(\n",
    "            os.path.join(checkpt, 'graph_edge_features.npy'))\n",
    "        graph_labels = np.load(os.path.join(checkpt, 'graph_labels.npy'))\n",
    "\n",
    "    return graph_node_features, graph_edge_features, graph_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpt doesnt exist, making it\n"
     ]
    }
   ],
   "source": [
    "graph_node_features, graph_edge_features, graph_labels = data_to_numpy1(\n",
    "    training_data, edge_cols, node_cols, date_range = a, pseudo_data = False, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_node_features, graph_edge_features, graph_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(graph_labels).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-02-01'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_range[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_date_range' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/alixdanglejan-chatillon/Code/PROJECT/ECSE552_Project/test.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alixdanglejan-chatillon/Code/PROJECT/ECSE552_Project/test.ipynb#ch0000015?line=0'>1</a>\u001b[0m get_date_range(\u001b[39m'\u001b[39m\u001b[39mLA_DATA_2018_02_to_2018_06.csv\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_date_range' is not defined"
     ]
    }
   ],
   "source": [
    "get_date_range('LA_DATA_2018_02_to_2018_06.csv')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
